ANNIE_FILE 1.0
# Network information, the next line identifies the type of network
# Constructing a network from a file which doesn't have the following identifier
# should result in an error 
# DO NOT MAKE FORMAT CHANGES TO THIS FILE
MultiLayerNetwork
INPUTS 400
OUTPUTS 1
MAX_LAYER_SIZE 1000 # There cannot be more than these many neurons in a layer

BEGIN_META_DATA
kk
END_META_DATA

# Below follow layer sizes, the last one is the same as OUTPUTS
# -------------------------------------------------------------------------
SIZE 26 # of layer 0
SIZE 1 # of layer 1
# Now follows information on the neural connections
# Basically, MAX_LAYER_SIZE puts an upper bound on the number of neurons in a layer
# so connections are specified as (label 1),(label 2),(weight) where 
# there is a connection from (label 1) --> (label 2) of weight (weight)
# The label of neurons is MAX_LAYER_SIZE*L+N where L is the layer number and N is the
# neuron number in that layer
# Label of input layer is 0, layer below it is 1 and so on
Biases
# Layer 0, 26 lines follow
-0.326502
-0.384348
0.548823
-0.593794
1.43708
-0.000495672
-0.212492
-0.371346
-0.0741737
1.95266
-0.499849
-0.0789351
0.110061
-1.02937
-0.537952
-0.389337
0.310781
-2.56153
-3.13821
1.17179
0.536386
-0.490442
-1.3525
-0.876938
-1.18414
-0.971615
# Layer 1, 1 lines follow
1.10798
Connections
0,1000,-0.155432
1,1000,0.526791
2,1000,0.00109933
3,1000,1.08803
4,1000,0.492344
5,1000,-0.154493
6,1000,-0.250178
7,1000,-0.503539
8,1000,-0.515682
9,1000,-0.389095
20,1000,0.156283
21,1000,0.496331
22,1000,0.109194
23,1000,0.498463
24,1000,0.349836
25,1000,-0.710454
26,1000,-0.603405
27,1000,-1.07483
28,1000,-1.26861
29,1000,-1.18521
65,1000,-0.205801
66,1000,-0.209238
67,1000,-0.476957
40,1000,0.727772
41,1000,-0.000510418
42,1000,-0.408897
43,1000,-0.565025
44,1000,-0.994685
45,1000,-0.697098
46,1000,-0.8509
47,1000,-0.996703
48,1000,-0.831126
49,1000,-1.33789
60,1000,0.486629
61,1000,0.109954
62,1000,-0.595774
63,1000,-0.676747
64,1000,-0.212589
129,1000,-0.379079
68,1000,-0.190667
69,1000,-0.867138
80,1000,0.808235
81,1000,0.00365922
82,1000,-0.149676
83,1000,0.471587
84,1000,-0.404094
85,1000,-0.170875
86,1000,0.177179
87,1000,-0.498588
88,1000,0.0898577
89,1000,-0.452782
100,1000,0.258237
101,1000,0.23956
102,1000,-0.478694
103,1000,0.0197689
104,1000,-0.3376
105,1000,-0.145052
106,1000,0.570013
107,1000,0.0337541
108,1000,0.602609
109,1000,-0.605232
120,1000,-0.22633
121,1000,-0.342299
122,1000,-0.0599631
123,1000,-0.730115
124,1000,-0.566423
125,1000,0.634262
126,1000,0.663244
127,1000,0.69015
128,1000,0.658429
140,1000,0.416559
141,1000,-0.166207
142,1000,-0.18397
143,1000,-0.339957
144,1000,0.356395
145,1000,0.488617
146,1000,0.162377
147,1000,0.256057
148,1000,0.263736
149,1000,-0.691149
160,1000,0.536765
161,1000,-0.173507
162,1000,-0.130144
163,1000,-0.742707
164,1000,-0.535797
165,1000,-0.220987
166,1000,-0.370333
167,1000,-0.401265
168,1000,-0.00201176
169,1000,-0.535317
180,1000,0.935332
181,1000,0.611909
182,1000,-0.167147
183,1000,-0.969198
184,1000,-1.05667
185,1000,-0.564897
186,1000,-0.535639
187,1000,-0.787158
188,1000,-0.349976
189,1000,-0.834465
10,1001,-0.324495
11,1001,0.0723621
12,1001,0.181802
13,1001,0.670382
14,1001,-0.140648
15,1001,1.13497
16,1001,2.06013
17,1001,1.8814
18,1001,2.69094
19,1001,-0.017828
30,1001,-2.32469
31,1001,-1.60805
32,1001,-0.350876
33,1001,-0.0731148
34,1001,-0.225892
35,1001,0
